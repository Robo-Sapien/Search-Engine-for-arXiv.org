Title,Authors,Abstract,Date,URL
"
Improved approximation algorithms for hitting 3-vertex paths","Samuel Fiorini, Gwenaël Joret, Oliver Schaudt"," We study the problem of deleting a minimum cost set of vertices from a given
vertex-weighted graph in such a way that the resulting graph has no induced
path on three vertices. This problem is often called cluster vertex deletion in
the literature and admits a straightforward 3-approximation algorithm since it
is a special case of the vertex cover problem on a 3-uniform hypergraph.
Recently, You, Wang, and Cao described an efficient 5/2-approximation algorithm
for the unweighted version of the problem. Our main result is a
9/4-approximation algorithm for arbitrary weights, using the local ratio
technique. We further conjecture that the problem admits a 2-approximation
algorithm and give some support for the conjecture. This is in sharp contrast
with the fact that the similar problem of deleting vertices to eliminate all
triangles in a graph is known to be UGC-hard to approximate to within a ratio
better than 3, as proved by Guruswami and Lee.
",(Submitted on 30 Aug 2018),https://arxiv.org/abs/1808.10370
"
Algorithms and Bounds for Drawing Directed Graphs","Giacomo Ortali, Ioannis G. Tollis"," In this paper we present a new approach to visualize directed graphs and
their hierarchies that completely departs from the classical four-phase
framework of Sugiyama and computes readable hierarchical visualizations that
contain the complete reachability information of a graph. Additionally, our
approach has the advantage that only the necessary edges are drawn in the
drawing, thus reducing the visual complexity of the resulting drawing.
Furthermore, most problems involved in our framework require only polynomial
time. Our framework offers a suite of solutions depending upon the
requirements, and it consists of only two steps: (a) the cycle removal step (if
the graph contains cycles) and (b) the channel decomposition and hierarchical
drawing step. Our framework does not introduce any dummy vertices and it keeps
the vertices of a channel vertically aligned. The time complexity of the main
drawing algorithms of our framework is $O(kn)$, where $k$ is the number of
channels, typically much smaller than $n$ (the number of vertices).
",(Submitted on 30 Aug 2018),https://arxiv.org/abs/1808.10364
"
Fully Dynamic MIS in Uniformly Sparse Graphs","Krzysztof Onak, Baruch Schieber, Shay Solomon, Nicole Wein"," We consider the problem of maintaining a maximal independent set (MIS) in a
dynamic graph subject to edge insertions and deletions. Recently, Assadi, Onak,
Schieber and Solomon (STOC 2018) showed that an MIS can be maintained in
sublinear (in the dynamically changing number of edges) amortized update time.
In this paper we significantly improve the update time for uniformly sparse
graphs. Specifically, for graphs with arboricity $\alpha$, the amortized update
time of our algorithm is $O(\alpha^2 \cdot \log^2 n)$, where $n$ is the number
of vertices. For low arboricity graphs, which include, for example, minor-free
graphs as well as some classes of `real world' graphs, our update time is
polylogarithmic. Our update time improves the result of Assadi et al. for all
graphs with arboricity bounded by $m^{3/8 - \epsilon}$, for any constant
$\epsilon > 0$. This covers much of the range of possible values for
arboricity, as the arboricity of a general graph cannot exceed $m^{1/2}$.
",(Submitted on 30 Aug 2018),https://arxiv.org/abs/1808.10316
"
Consistent Sampling with Replacement",Ronald L. Rivest," We describe a very simple method for `consistent sampling' that allows for
sampling with replacement. The method extends previous approaches to consistent
sampling, which assign a pseudorandom real number to each element, and sample
those with the smallest associated numbers. When sampling with replacement, our
extension gives the item sampled a new, larger, associated pseudorandom number,
and returns it to the pool of items being sampled.
",(Submitted on 29 Aug 2018),https://arxiv.org/abs/1808.10016
"
Submodular Maximization with Packing Constraints in Parallel","Alina Ene, Huy L. Nguyen, Adrian Vladu"," We consider the problem of maximizing the multilinear extension of a
submodular function subject to packing constraints in parallel. For monotone
functions, we obtain a $1-1/e-\epsilon$ approximation using
$O(\log(n/\epsilon)\log(m)/\epsilon^2)$ rounds of adaptivity and evaluations of
the function and its gradient, where $m$ is the number of packing constraints
and $n$ is the number of variables. For non-monotone functions, we obtain a
$1/e-\epsilon$ approximation using
$O(\log(n/\epsilon)\log(1/\epsilon)\log(n+m)/\epsilon^2)$ rounds of adaptivity
and evaluations of the function and its gradient. Our results apply more
generally to the problem of maximizing a diminishing returns submodular
(DR-submodular) function subject to packing constraints.
",(Submitted on 29 Aug 2018),https://arxiv.org/abs/1808.09987
"
Differentially Private Change-Point Detection","Rachel Cummings, Sara Krehbiel, Yajun Mei, Rui Tuo, Wanrong Zhang"," The change-point detection problem seeks to identify distributional changes
at an unknown change-point k* in a stream of data. This problem appears in many
important practical settings involving personal data, including
biosurveillance, fault detection, finance, signal detection, and security
systems. The field of differential privacy offers data analysis tools that
provide powerful worst-case privacy guarantees. We study the statistical
problem of change-point detection through the lens of differential privacy. We
give private algorithms for both online and offline change-point detection,
analyze these algorithms theoretically, and provide empirical validation of our
results.
",(Submitted on 29 Aug 2018),https://arxiv.org/abs/1808.10056
"
Recent progress on scaling algorithms and applications","Ankit Garg, Rafael Oliveira"," Scaling problems have a rich and diverse history, and thereby have found
numerous applications in several fields of science and engineering. For
instance, the matrix scaling problem has had applications ranging from
theoretical computer science to telephone forecasting, economics, statistics,
optimization, among many other fields. Recently, a generalization of matrix
scaling known as operator scaling has found applications in non-commutative
algebra, invariant theory, combinatorics and algebraic complexity; and a
further generalization (tensor scaling) has found more applications in quantum
information theory, geometric complexity theory and invariant theory. In this
survey, we will describe in detail the scaling problems mentioned above,
showing how alternating minimization algorithms naturally arise in this
setting, and we shall present a general framework to rigorously analyze such
algorithms. These simple problems and algorithms are not just applicable to
diverse mathematical and CS areas, but also serve to bring out deep connections
between them. As this framework makes extensive use of concepts from invariant
theory, we also provide a very gentle introduction to basic concepts of
invariant theory and how they are used to analyze alternating minimization
algorithms for the scaling problems. This survey is intended for a general
computer science audience, and the only background required is basic knowledge
of calculus and linear algebra, thereby making it accessible to graduate
students and even to advanced undergraduates.
",(Submitted on 29 Aug 2018),https://arxiv.org/abs/1808.09669
"
Approximately counting bases of bicircular matroids","Heng Guo, Mark Jerrum"," We give a fully polynomial-time randomised approximation scheme (FPRAS) for
the number of bases in a bicircular matroids. This is a natural class of
matroids for which counting bases exactly is #P-hard and yet approximate
counting can be done efficiently.
",(Submitted on 28 Aug 2018),https://arxiv.org/abs/1808.09548
"
Enumerating Top-k Quasi-Cliques","Seyed-Vahid Sanei-Mehri, Apurba Das, Srikanta Tirthapura"," Quasi-cliques are dense incomplete subgraphs of a graph that generalize the
notion of cliques. Enumerating quasi-cliques from a graph is a robust way to
detect densely connected structures with applications to bio-informatics and
social network analysis. However, enumerating quasi-cliques in a graph is a
challenging problem, even harder than the problem of enumerating cliques. We
consider the enumeration of top-k degree-based quasi-cliques, and make the
following contributions: (1) We show that even the problem of detecting if a
given quasi-clique is maximal (i.e. not contained within another quasi-clique)
is NP-hard (2) We present a novel heuristic algorithm KernelQC to enumerate the
k largest quasi-cliques in a graph. Our method is based on identifying kernels
of extremely dense subgraphs within a graph, following by growing subgraphs
around these kernels, to arrive at quasi-cliques with the required densities
(3) Experimental results show that our algorithm accurately enumerates
quasi-cliques from a graph, is much faster than current state-of-the-art
methods for quasi-clique enumeration (often more than three orders of magnitude
faster), and can scale to larger graphs than current methods.
",(Submitted on 28 Aug 2018),https://arxiv.org/abs/1808.09531
"
Level Planarity: Transitivity vs. Even Crossings","Guido Brückner, Ignaz Rutter, Peter Stumpf"," Recently, Fulek et al. have presented Hanani-Tutte results for (radial) level
planarity, i.e., a graph is (radial) level planar if it admits a (radial) level
drawing where any two (independent) edges cross an even number of times. We
show that the 2-Sat formulation of level planarity testing due to Randerath et
al. is equivalent to the strong Hanani-Tutte theorem for level planarity.
Further, we show that this relationship carries over to radial level planarity,
which yields a novel polynomial-time algorithm for testing radial level
planarity.
",(Submitted on 29 Aug 2018),https://arxiv.org/abs/1808.09931
"
Mining (maximal) span-cores from temporal networks","Edoardo Galimberti, Alain Barrat, Francesco Bonchi, Ciro Cattuto, Francesco Gullo"," When analyzing temporal networks, a fundamental task is the identification of
dense structures (i.e., groups of vertices that exhibit a large number of
links), together with their temporal span (i.e., the period of time for which
the high density holds). We tackle this task by introducing a notion of
temporal core decomposition where each core is associated with its span: we
call such cores span-cores.
",(Submitted on 28 Aug 2018),https://arxiv.org/abs/1808.09376
"
Shortest Paths with Ordinal Weights","Luca E. Schäfer, Tobias Dietz, Nicolas Fröhlich, Stefan Ruzika, José Rui Figueira"," We investigate the single-source-single-destination ""shortest"" paths problem
in acyclic graphs with ordinal weighted arc costs. We define the concepts of
ordinal dominance and efficiency for paths and their associated ordinal levels,
respectively. Further, we show that the number of ordinally non-dominated paths
vectors from the source node to every other node in the graph is polynomially
bounded and we propose a polynomial time labeling algorithm for solving the
problem of finding the set of ordinally non-dominated paths vectors from source
to sink.
",(Submitted on 28 Aug 2018),https://arxiv.org/abs/1808.09410
"
An Issue in the Martingale Analysis of the Influence Maximization  Algorithm IMM",Wei Chen," This paper explains a subtle issue in the martingale analysis of the IMM
algorithm, a state-of-the-art influence maximization algorithm. Two workarounds
are proposed to fix the issue, both requiring minor changes on the algorithm
and incur a slight penalty on the running time of the algorithm.
",(Submitted on 24 Aug 2018),https://arxiv.org/abs/1808.09363
"
On Some Combinatorial Problems in Cographs","Kona Harshita, N. Sadagopan"," The family of graphs that can be constructed from isolated vertices by
disjoint union and graph join operations are called cographs. These graphs can
be represented in a tree-like representation termed parse tree or cotree. In
this paper, we study some popular combinatorial problems restricted to
cographs. We first present a structural characterization of minimal vertex
separators in cographs. Further, we show that listing all minimal vertex
separators and the complexity of some constrained vertex separators are
polynomial-time solvable in cographs. We propose polynomial-time algorithms for
connectivity augmentation problems and its variants in cographs, preserving the
cograph property. Finally, using the dynamic programming paradigm, we present a
generic framework to solve classical optimization problems such as the longest
path, the Steiner path and the minimum leaf spanning tree problems restricted
to cographs, our framework yields polynomial-time algorithms for all three
problems.
",(Submitted on 28 Aug 2018),https://arxiv.org/abs/1808.09117
"
Finding events in temporal networks: Segmentation meets densest-subgraph  discovery","Polina Rozenshtein, Francesco Bonchi, Aristides Gionis, Mauro Sozio, Nikolaj Tatti"," In this paper we study the problem of discovering a timeline of events in a
temporal network. We model events as dense subgraphs that occur within
intervals of network activity. We formulate the event-discovery task as an
optimization problem, where we search for a partition of the network timeline
into k non-overlapping intervals, such that the intervals span subgraphs with
maximum total density. The output is a sequence of dense subgraphs along with
corresponding time intervals, capturing the most interesting events during the
network lifetime.
",(Submitted on 28 Aug 2018),https://arxiv.org/abs/1808.09317
"
A Quantum Interior Point Method for LPs and SDPs","Iordanis Kerenidis, Anupam Prakash"," We present a quantum interior point method with worst case running time
$\widetilde{O}(\frac{n^{2.5}}{\xi^{2}} \mu \kappa^3 \log (1/\epsilon))$ for
SDPs and $\widetilde{O}(\frac{n^{1.5}}{\xi^{2}} \mu \kappa^3 \log
(1/\epsilon))$ for LPs, where the output of our algorithm is a pair of matrices
$(S,Y)$ that are $\epsilon$-optimal $\xi$-approximate SDP solutions. The factor
$\mu$ is at most $\sqrt{2}n$ for SDPs and $\sqrt{2n}$ for LP's, and $\kappa$ is
an upper bound on the condition number of the intermediate solution matrices.
For the case where the intermediate matrices for the interior point method are
well conditioned, our method provides a polynomial speedup over the best known
classical SDP solvers and interior point based LP solvers, which have a worst
case running time of $O(n^{6})$ and $O(n^{3.5})$ respectively. Our results
build upon recently developed techniques for quantum linear algebra and pave
the way for the development of quantum algorithms for a variety of applications
in optimization and machine learning.
",(Submitted on 28 Aug 2018),https://arxiv.org/abs/1808.09266
"
Turning Cliques into Paths to Achieve Planarity","Patrizio Angelini, Peter Eades, Seok-Hee Hong, Karsten Klein, Stephen Kobourov, Giuseppe Liotta, Alfredo Navarra, Alessandra Tappini"," Motivated by hybrid graph representations, we introduce and study the
following beyond-planarity problem, which we call $h$-Clique2Path Planarity:
Given a graph $G$, whose vertices are partitioned into subsets of size at most
$h$, each inducing a clique, remove edges from each clique so that the subgraph
induced by each subset is a path, in such a way that the resulting subgraph of
$G$ is planar. We study this problem when $G$ is a simple topological graph,
and establish its complexity in relation to $k$-planarity. We prove that
$h$-Clique2Path Planarity is NP-complete even when $h=4$ and $G$ is a simple
$3$-plane graph, while it can be solved in linear time, for any $h$, when $G$
is $1$-plane.
",(Submitted on 27 Aug 2018 (,https://arxiv.org/abs/1808.08925
"
Explicit 3-colorings for exponential graphs","Adrien Argento, Alantha Newman"," Let $H=(V,E)$ denote a simple, undirected graph. The 3-coloring exponential
graph on $H$ is the graph whose vertex set corresponds to all (not necessarily
proper) 3-colorings of $H$. We denote this graph by $K_3^H$. Two vertices of
$K_3^H$, corresponding to colorings $f$ and $g$ of $H$, are connected by an
edge in $K_3^H$ if $f(i) \neq g(j)$ for all $ij \in E$. El-Zahar and Sauer
showed that when $H$ is 4-chromatic, $K_3^H$ is
3-chromatic~\cite{el1985chromatic}. Based on this work, Tardif gave an
algorithm to (properly) 3-color $K_3^H$ whose complexity is polynomial in the
size of $K_3^H$~\cite{tardifAlg}. Tardif then asked if there is an algorithm in
which the complexity of assigning a color to a vertex of $K_3^H$ is polynomial
in the size of $H$. We present such an algorithm, answering Tardif's question
affirmatively.
",(Submitted on 27 Aug 2018),https://arxiv.org/abs/1808.08691
"
Empirical Analysis of Common Subgraph Isomorphism Approaches to the  Lost-in-Space Star Identification Problem","Glenn Galvizo, Lipyeow Lim"," The process of identifying stars is integral toward stellar based orientation
determination in spacecraft. Star identification involves matching points in an
image of the sky with stars in an astronomical catalog. A unified framework for
identification was created and used to analyze six variations of methods based
on their approach to star set identification, obtaining a single image to
catalog star set match, and uniquely mapping each star in a image star set to a
catalog star set. Each method was presented an artificial image, and aspects
that were interchangeable among each process were normalized. Given an image
with false stars, the Pyramid method has the highest average accuracy and is
the fastest of the six. Given an image where each star's true position is
distributed randomly (Gaussian noise), the Spherical Triangle method's accuracy
is the least sensitive.
",(Submitted on 27 Aug 2018),https://arxiv.org/abs/1808.08686
"
Towards Tight Approximation Bounds for Graph Diameter and Eccentricities","Arturs Backurs, Liam Roditty, Gilad Segal, Virginia Vassilevska Williams, Nicole Wein"," Among the most important graph parameters is the Diameter, the largest
distance between any two vertices. There are no known very efficient algorithms
for computing the Diameter exactly. Thus, much research has been devoted to how
fast this parameter can be approximated. Chechik et al. showed that the
diameter can be approximated within a multiplicative factor of $3/2$ in
$\tilde{O}(m^{3/2})$ time. Furthermore, Roditty and Vassilevska W. showed that
unless the Strong Exponential Time Hypothesis (SETH) fails, no
$O(n^{2-\epsilon})$ time algorithm can achieve an approximation factor better
than $3/2$ in sparse graphs. Thus the above algorithm is essentially optimal
for sparse graphs for approximation factors less than $3/2$. It was, however,
completely plausible that a $3/2$-approximation is possible in linear time. In
this work we conditionally rule out such a possibility by showing that unless
SETH fails no $O(m^{3/2-\epsilon})$ time algorithm can achieve an approximation
factor better than $5/3$.
",(Submitted on 26 Aug 2018),https://arxiv.org/abs/1808.08494
"
Simple Graph Coloring Algorithms for Congested Clique and Massively  Parallel Computation","Manuela Fischer, Mohsen Ghaffari, Jara Uitto"," We present a very simple randomized partitioning procedure for graph
coloring, which leads to simplification or improvements of some recent
distributed and parallel coloring algorithms. In particular, we get a simple
$(\Delta+1)$ coloring algorithm with round complexity $O(\log^* \Delta)$ in the
CONGESTED CLIQUE model of distributed computing. This matches the bound of
Parter and Su [DISC'18], which improved on the $O(\log\log \Delta \log^*
\Delta)$-round algorithm of Parter [ICALP'18]. Moreover, the same random
partitioning leads to a $(\Delta+1)$ coloring algorithm with round complexity
$O(\log^* \Delta+ \sqrt{\log\log n})$ in the Massively Parallel Computation
(MPC) model with strongly sublinear memory, which is the first
sublogarithmic-time algorithm in this regime. This algorithm uses a memory of
$O(n^{\alpha})$ per machine and a total memory of $O(m+ n^{1+\varepsilon})$,
for any desirable constants $\alpha,\varepsilon>0$, where $m$ is the size of
the graph.
",(Submitted on 25 Aug 2018),https://arxiv.org/abs/1808.08419
"
Ranked Schröder Trees","Olivier Bodini, Antoine Genitrini, Mehdi Naima"," In biology, a phylogenetic tree is a tool to represent the evolutionary
relationship between species. Unfortu- nately, the classical Schr\""oder tree
model is not adapted to take into account the chronology between the branching
nodes. In particular, it does not answer the question: how many different
phylogenetic stories lead to the creation of n species and what is the average
time to get there? In this paper, we enrich this model in two distinct ways in
order to obtain two ranked tree models for phylogenetics, i.e. models coding
chronology. For that purpose, we first develop a model of (strongly) increasing
Schr\""oder trees, symbolically de- scribed in the classical context of
increasing labeling. Then we introduce a generalization for the labeling with
some unusual order constraint in Analytic Combinatorics (namely the weakly
increasing trees). Although these models are direct extensions of the
Schr\""oder tree model, it appears that they are also in one-to-one
correspondence with several classical combinatorial objects. Through the paper,
we present these links, exhibit some parameters in typical large trees and
conclude the studies with efficient uniform samplers.
",(Submitted on 25 Aug 2018),https://arxiv.org/abs/1808.08376
"
Fair redistricting is hard","Richard Kueng, Dustin G. Mixon, Soledad Villar"," Gerrymandering is a long-standing issue within the U.S. political system, and
it has received scrutiny recently by the U.S. Supreme Court. In this note, we
prove that deciding whether there exists a fair redistricting among legal maps
is NP-hard. To make this precise, we use simplified notions of ""legal"" and
""fair"" that account for desirable traits such as geographic compactness of
districts and sufficient representation of voters. The proof of our result is
inspired by the work of Mahanjan, Minbhorkar and Varadarajan that proves that
planar k-means is NP-hard.
",(Submitted on 27 Aug 2018),https://arxiv.org/abs/1808.08905
"
Detecting strong cliques","Ademir Hujdurović, Martin Milanič, Bernard Ries"," A strong clique in a graph is a clique intersecting every maximal independent
set. We study the computational complexity of six algorithmic decision problems
related to strong cliques in graphs and almost completely determine their
complexity in the classes of chordal graphs, weakly chordal graphs, line graphs
and their complements, and graphs of maximum degree at most three. Our results
rely on connections with matchings and relate to several graph properties
studied in the literature, including well-covered graphs, localizable graphs,
and general partition graphs.
",(Submitted on 24 Aug 2018),https://arxiv.org/abs/1808.08817
"
Solving Partition Problems Almost Always Requires Pushing Many Vertices  Around","Iyad Kanj, Christian Komusiewicz, Manuel Sorge, Erik Jan van Leeuwen"," A fundamental graph problem is to recognize whether the vertex set of a graph
G can be bipartitioned into sets A and B such that G[A] and G[B] satisfy
properties P_A and P_B, respectively. This so-called (P_A,P_B)-RECOGNITION
problem generalizes amongst others the recognition of 3-colorable, bipartite,
split, and monopolar graphs. A powerful algorithmic technique that can be used
to obtain fixed-parameter algorithms for many cases of (P_A,P_B)-RECOGNITION,
as well as several other problems, is the pushing process. For bipartition
problems, the process starts with an ""almost correct"" bipartition (A',B'), and
pushes appropriate vertices from A' to B' and vice versa to eventually arrive
at a correct bipartition.
",(Submitted on 27 Aug 2018),https://arxiv.org/abs/1808.08772
"
One (more) line on the most Ancient Algorithm in History",Ilya Volkovich," We give a new simple and short (""one-line"") analysis for the runtime of the
well-known Euclidean Algorithm. While very short simple, the obtained upper
bound in near-optimal.
",(Submitted on 23 Aug 2018),https://arxiv.org/abs/1808.07957
